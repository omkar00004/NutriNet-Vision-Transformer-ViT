# NutriNet â€“ Vision Transformer (ViT) for Food Classification

Implemented the ViT architecture from scratch in PyTorch, based on "An Image is Worth 16x16 Words." Built a food image classification pipeline with patch embedding, positional encoding, and transformer encoder blocks (MSA, LayerNorm, MLP, residuals). Trained on a multi-class dataset (Food 101) using Adam optimizer with learning rate warmup and cross-entropy loss. Added a nutritional estimation module providing calorie content and performed comparisons with CNN baselines, showcasing ViT's effectiveness in food recognition.

Technologies Used: PyTorch, Deep Learning, Computer Vision, Transformer Architectures.
